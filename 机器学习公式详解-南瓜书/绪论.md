# 绪论

## 基本术语辨析

### 样本

抽象为向量的，对某事物或事件的描述。任何事物可提取其“特征”作为向量的维度，对某一特征的取值，即为“属性值”，体现在向量的大小

> 从事物事件中提取特征等，与特征处理相关的工作，称为“特征工程”

### 样本空间

由于样本采用的是标明各个特征取值的"特征向量"来进行表示，有向量便会有向量所在的空间，因此称表示样本的特征向量所在的空间为样本空间

### 数据集

数据集通常用集合来表示。一般同一份数据集中的每个样本都含有相同个数的特征。

### 模型

机器学习的一般流程如下：

1. 收集若干样本（假设此时有100个）
2. 将其分为训练样本（80个）和测试样本（20个），其中80个训练样本构成的集合称为"训练集"，20个测试样本构成的集合称为"测试集"
3. 选用某个机器学习算法，让其在训练集上进行"学习"（或称为"训练"）
4. 产出得到"模型"（或称为"学习器"）
5. 用测试集来测试模型的效果

> 执行以上流程时，表示我们已经默认样本的背后是存在某种潜在的规律，我们称这种潜在的规律为"真相"或者"真实"
> 
> 当我们应用某个机器学习算法来学习时，产出得到的模型便是该算法所找到的它自己认为的规律，由于该规律通常并不一定就是所谓的真相，所以也将其称为"假设"
> 
> 通常机器学习算法都有可配置的参数，同一个机器学习算法，使用不同的参数配置或者不同的训练集，训练得到的模型通常都不同

### 标记
与想要得到的规律相关的信息，称为"标记"。标记所在的空间称为"标记空间"或"输出空间

根据标记的取值类型不同，可将机器学习任务分为以下两类：

- 当标记取值为离散型时，称此类任务为**分类**。
    - 当分类的类别只有两个时，称此类任务为**二分类**，通常称其中一个为"正类"，另一个为"反类"或"负类"；
    - 当分类的类别超过两个时，称此类任务为**多分类**。由于标记也属于样本的一部分，通常也需要参与运算，因此也需要将其数值化，
- 当标记取值为连续型时，称此类任务为**回归**。
    - 例如学习预测西瓜的成熟度、学习预测未来的房价等。由于是连续型，因此标记的所有可能取值无法直接罗列，通常只有取值范围，回归任务的标记取值范围通常是整个实数域

根据是否有用到标记信息，可将机器学习任务分为以下两类：
- 在模型训练阶段有用到标记信息时，称此类任务为**监督学习**，例如线性模型
- 在模型训练阶段没用到标记信息时，称此类任务为**无监督学习**，例如聚类

### 泛化

由于机器学习的目标是根据已知来对未知做出尽可能准确的判断，因此对未知事物判断的准确与否才是衡量一个模型好坏的关键，称此为"泛化"能力

### 分布

此处的"分布"指的是概率论中的概率分布

通常假设样本空间服从一个未知"分布"D，而我们收集到的每个样本都是独立地从该分布中采样得到，即"独立同分布"。

通常收集到的样本越多，越能从样本中反推出D的信息，即越接近真相。

此假设属于机器学习中的经典假设，在后续学习机器学习算法过程中会经常用到。

# 假设空间
数据作为训练集可以有多个假设空间，且在不同的假设空间中都有可能学得能够拟合训练集的模型，我们将所有能够拟合训练集的模型构成的集合称为"版本空间"。

假设空间更像是对某一事件“走势”的预测结果，例如分析某一事件发生的概率，会因为其他事件是否发生而产生影响，那么就产生了一个巨大的遐想空间，产生无数种可能性

每一种可能性都是一个“假设空间”，而所有走向“正面”，符合预期的概率和结果的可能性，组成集合，即为“版本空间”

# 归纳偏好

根据所选择的算法不同，不同的机器学习算法学得的模型不同，即“有不同的偏好”，我们称为"归纳偏好"
如何确定哪种偏好更优，最常用的方法则是基于模型在测试集上的表现来评判